{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152cde75-4b5f-4b93-a4bc-f7bea7c6eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/rameshjayasekaran/Downloads/ai-job-search-assistant\n",
      "Files in current directory: ['ai-job-search-assistant-notebook.ipynb', 'Untitled.ipynb', 'README.md', 'secrets.txt', '.ipynb_checkpoints', '.git']\n",
      "✅ Gemini API key setup complete from secrets.txt. Key starts with: AIza\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Files in current directory: {os.listdir(os.getcwd())}\")\n",
    "\n",
    "dotenv_path = Path('.') / 'secrets.txt'\n",
    "\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY is None:\n",
    "    print(\n",
    "        f\"❌ Authentication Error: GOOGLE_API_KEY not found in the '{dotenv_path}' file.\"\n",
    "    )\n",
    "    print(\"Please check the file name, location, and the variable naming inside the file.\")\n",
    "else:\n",
    "    print(f\"✅ Gemini API key setup complete from {dotenv_path}. Key starts with: {GOOGLE_API_KEY[:4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbbfd82-eb5b-45fd-ba61-43f5e8187677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (2.12.4)\n",
      "Requirement already satisfied: pandas in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: fastapi in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (0.121.2)\n",
      "Requirement already satisfied: uvicorn in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (0.38.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from fastapi) (0.49.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from fastapi) (0.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from starlette<0.50.0,>=0.40.0->fastapi) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from uvicorn) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rameshjayasekaran/py312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydantic pandas fastapi uvicorn python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ed3133-5e2a-41f6-a1c9-ec7c590a098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re, uuid, time\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "LOG_DIR = \"logs\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4d40fb-0f41-4e75-871e-7ea82704609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_call_gemini(prompt: str, temperature: float = 0.0, max_tokens: int = 512) -> str:\n",
    "    \"\"\"\n",
    "    Simple deterministic mock used for development.\n",
    "    Replace with actual Vertex AI / Gemini call when ready.\n",
    "    \"\"\"\n",
    "    # Very small heuristic responses for key prompt types.\n",
    "    if \"EXTRACT_RESUME_JSON\" in prompt:\n",
    "        # return minimal JSON string (example)\n",
    "        return json.dumps({\n",
    "            \"name\":\"Arun Kumar\",\n",
    "            \"title\":\"Backend Developer\",\n",
    "            \"emails\":[\"arun@example.com\"],\n",
    "            \"phones\":[\"+919900112233\"],\n",
    "            \"skills\":[\"Java\",\"Spring Boot\",\"SQL\",\"REST\",\"Docker\"],\n",
    "            \"years_experience\":4,\n",
    "            \"experience\":[\n",
    "                {\"title\":\"Backend Developer\",\"company\":\"Acme\",\"start\":\"2021-06\",\"end\":\"2024-09\",\"bullets\":[\"Built REST APIs using Spring Boot.\"]}\n",
    "            ],\n",
    "            \"education\":[\"B.Tech Computer Science\"]\n",
    "        })\n",
    "    if \"TAILOR_BULLETS\" in prompt:\n",
    "        return json.dumps({\n",
    "            \"bullets\": [\n",
    "                \"Designed and implemented RESTful APIs using Spring Boot, improving response time by 30%.\",\n",
    "                \"Built database schemas and optimized SQL queries to reduce average query latency by 25%.\"\n",
    "            ]\n",
    "        })\n",
    "    if \"COVER_LETTER\" in prompt:\n",
    "        return \"Dear Hiring Manager,\\n\\nI am excited to apply for the Backend Developer role at Acme... (sample cover letter)\\n\"\n",
    "    if \"MATCH_EXPLAIN\" in prompt:\n",
    "        return json.dumps({\"match_score\":0.78, \"reasons\":[\"Matches 5/7 skills\"], \"gaps\":[\"System design\"]})\n",
    "    # default\n",
    "    return \"[MOCK] \" + (prompt[:400].replace(\"\\n\",\" \") + \" ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c7d61e-144b-43a4-a962-73d911ccd213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load jobs from jobs.json (you can replace content)\n",
    "with open(\"data/jobs.json\",\"r\") as f:\n",
    "    JOBS = json.load(f)\n",
    "len(JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b832bf-5741-457c-94a3-687b0165f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resume(BaseModel):\n",
    "    name: str = None\n",
    "    title: str = None\n",
    "    emails: List[str] = []\n",
    "    phones: List[str] = []\n",
    "    skills: List[str] = []\n",
    "    years_experience: int = 0\n",
    "    experience: List[Dict[str, Any]] = []\n",
    "    education: List[str] = []\n",
    "\n",
    "class Job(BaseModel):\n",
    "    id: str\n",
    "    title: str\n",
    "    company: str\n",
    "    location: str\n",
    "    remote: bool = False\n",
    "    skills: List[str] = []\n",
    "    seniority: str = \"mid\"\n",
    "    salary: str = \"\"\n",
    "    description: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8671770-626f-45c6-a986-90ff2c4c8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resume Agent\n",
    "def resume_text_to_json(resume_text: str) -> dict:\n",
    "    # quick regex heuristics (email/phone), otherwise fallback to LLM\n",
    "    emails = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", resume_text)\n",
    "    phones = re.findall(r\"\\+?\\d[\\d \\-]{7,}\\d\", resume_text)\n",
    "    # try to extract skills heuristically: look for \"Skills:\" line\n",
    "    skills = []\n",
    "    m = re.search(r\"Skills[:\\s]+(.+)\", resume_text, re.IGNORECASE)\n",
    "    if m:\n",
    "        skills = [s.strip() for s in re.split(r\",|\\||;\", m.group(1)) if s.strip()]\n",
    "    # If minimal data only, call LLM mock to get structured JSON\n",
    "    if len(skills) < 2 or not emails:\n",
    "        prompt = f\"EXTRACT_RESUME_JSON\\n\\n{resume_text}\"\n",
    "        out = mock_call_gemini(prompt, temperature=0)\n",
    "        parsed = json.loads(out)\n",
    "        return parsed\n",
    "    # otherwise build simple JSON\n",
    "    parsed = {\n",
    "        \"name\": resume_text.splitlines()[0].strip() if resume_text else \"Unknown\",\n",
    "        \"title\": None,\n",
    "        \"emails\": emails,\n",
    "        \"phones\": phones,\n",
    "        \"skills\": skills,\n",
    "        \"years_experience\": 3,\n",
    "        \"experience\": [],\n",
    "        \"education\": []\n",
    "    }\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43a0c1a5-5b35-457c-b959-712886466e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Agent\n",
    "def search_jobs(query: str=\"\", filters: Dict[str,Any]=None, top_k: int=20) -> List[Dict]:\n",
    "    filters = filters or {}\n",
    "    q = query.lower()\n",
    "    candidates = []\n",
    "    for job in JOBS:\n",
    "        score = 0\n",
    "        # keyword match between query and job title/desc\n",
    "        if q:\n",
    "            if q in job[\"title\"].lower() or q in job[\"company\"].lower() or q in job[\"description\"].lower():\n",
    "                score += 2\n",
    "        # simple filter checks\n",
    "        if filters.get(\"remote\") is True and job.get(\"remote\"):\n",
    "            score += 1\n",
    "        if \"location\" in filters and filters[\"location\"].lower() in job[\"location\"].lower():\n",
    "            score += 1\n",
    "        candidates.append((score, job))\n",
    "    # sort by score desc\n",
    "    candidates = sorted(candidates, key=lambda x: x[0], reverse=True)\n",
    "    return [c[1] for c in candidates[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922651c8-e1ad-4640-bbe1-a31928594424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching Agent\n",
    "def match_resume_to_jobs(resume_json: dict, candidate_jobs: List[dict], top_k=10) -> List[dict]:\n",
    "    r_skills = set([s.lower() for s in resume_json.get(\"skills\",[])])\n",
    "    ranked = []\n",
    "    for job in candidate_jobs:\n",
    "        j_skills = set([s.lower() for s in job.get(\"skills\",[])])\n",
    "        if len(j_skills)==0:\n",
    "            skill_score = 0.0\n",
    "        else:\n",
    "            skill_score = len(r_skills & j_skills) / len(j_skills)\n",
    "        seniority_penalty = 0.0\n",
    "        # simple seniority mapping\n",
    "        if job.get(\"seniority\",\"mid\")==\"senior\" and resume_json.get(\"years_experience\",0) < 5:\n",
    "            seniority_penalty = 0.2\n",
    "        score = skill_score - seniority_penalty\n",
    "        rationale = f\"skill_match={len(r_skills & j_skills)}/{len(j_skills)}; seniority_penalty={seniority_penalty}\"\n",
    "        ranked.append({\"job\":job, \"score\": round(float(score),3), \"rationale\":rationale})\n",
    "    ranked = sorted(ranked, key=lambda x: x[\"score\"], reverse=True)\n",
    "    return ranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f008ffe-96ad-45ea-8670-edb79750c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tailor agent\n",
    "\n",
    "def tailor_resume_bullets(resume_json: dict, job_json: dict) -> List[str]:\n",
    "    prompt = f\"TAILOR_BULLETS\\nResumeJSON: {json.dumps(resume_json)}\\nJobJSON: {json.dumps(job_json)}\"\n",
    "    out = mock_call_gemini(prompt, temperature=0)\n",
    "    parsed = json.loads(out)\n",
    "    return parsed.get(\"bullets\", [])\n",
    "\n",
    "def generate_cover_letter(resume_json: dict, job_json: dict) -> str:\n",
    "    prompt = f\"COVER_LETTER\\nResumeJSON: {json.dumps(resume_json)}\\nJobJSON: {json.dumps(job_json)}\"\n",
    "    return mock_call_gemini(prompt, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70396fa5-b3d5-4dd8-8bdd-4dd6f97bc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explainer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde40266-7acf-42b9-9bf1-4f05c3d1978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_match(resume_json: dict, job_json: dict) -> dict:\n",
    "    prompt = f\"MATCH_EXPLAIN\\nResumeJSON: {json.dumps(resume_json)}\\nJobJSON: {json.dumps(job_json)}\"\n",
    "    out = mock_call_gemini(prompt, temperature=0)\n",
    "    return json.loads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04aaceee-a2d6-4297-a81c-60f44452f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKER_FILE = \"data/tracker.json\"\n",
    "if not os.path.exists(\"data\"): os.makedirs(\"data\", exist_ok=True)\n",
    "if not os.path.exists(TRACKER_FILE):\n",
    "    with open(TRACKER_FILE,\"w\") as f:\n",
    "        json.dump([], f)\n",
    "\n",
    "def add_application(resume_name: str, job_id: str, artifacts: dict):\n",
    "    with open(TRACKER_FILE,\"r\") as f:\n",
    "        arr = json.load(f)\n",
    "    rec = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"applied_at\": datetime.utcnow().isoformat(),\n",
    "        \"resume_name\": resume_name,\n",
    "        \"job_id\": job_id,\n",
    "        \"artifacts\": artifacts\n",
    "    }\n",
    "    arr.append(rec)\n",
    "    with open(TRACKER_FILE,\"w\") as f:\n",
    "        json.dump(arr, f, indent=2)\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28f1bdd6-4a53-44d6-9cac-faf665344049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed resume: {'name': 'Rohit Menon', 'title': None, 'emails': ['rohit.m@example.com'], 'phones': [], 'skills': ['Python', 'Pandas', 'Scikit-learn', 'SQL', 'Visualization'], 'years_experience': 3, 'experience': [], 'education': []}\n",
      "Top matches:\n",
      "1.0 Data Scientist DataSense -> skill_match=4/4; seniority_penalty=0.0\n",
      "Tailored bullets: ['Designed and implemented RESTful APIs using Spring Boot, improving response time by 30%.', 'Built database schemas and optimized SQL queries to reduce average query latency by 25%.']\n",
      "Cover letter (excerpt): Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Backend Developer role at Acme... (sample cover letter)\n",
      "\n",
      "Application recorded: 36f4aa5d-1030-48af-a2fa-a6b6f1ccdc8e\n",
      "0.333 QA Automation Engineer TestHive -> skill_match=1/3; seniority_penalty=0.0\n",
      "0.25 Backend Developer Acme Tech -> skill_match=1/4; seniority_penalty=0.0\n",
      "0.25 Software Engineer - Backend Nimbus Labs -> skill_match=1/4; seniority_penalty=0.0\n",
      "0.25 ML Engineer VisionX -> skill_match=1/4; seniority_penalty=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/fsxydgs17fb25rb7jrlvhmrh0000gn/T/ipykernel_2278/16821313.py:12: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"applied_at\": datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "#End to End Demo run\n",
    "\n",
    "# load a sample resume text (I'll provide 3 samples below)\n",
    "sample_resume_text = open(\"data/sample_resume_3.txt\").read()\n",
    "resume_json = resume_text_to_json(sample_resume_text)\n",
    "print(\"Parsed resume:\", resume_json)\n",
    "\n",
    "candidates = search_jobs(query=\"Data Scientist\", filters={\"remote\":True}, top_k=20)\n",
    "ranked = match_resume_to_jobs(resume_json, candidates, top_k=5)\n",
    "print(\"Top matches:\")\n",
    "for r in ranked:\n",
    "    jid = r[\"job\"][\"id\"]\n",
    "    print(r[\"score\"], r[\"job\"][\"title\"], r[\"job\"][\"company\"], \"->\", r[\"rationale\"])\n",
    "    # generate bullets for top1 only\n",
    "    if r==ranked[0]:\n",
    "        bullets = tailor_resume_bullets(resume_json, r[\"job\"])\n",
    "        letter = generate_cover_letter(resume_json, r[\"job\"])\n",
    "        print(\"Tailored bullets:\", bullets)\n",
    "        print(\"Cover letter (excerpt):\", letter[:300])\n",
    "        rec = add_application(resume_json.get(\"name\",\"unknown\"), jid, {\"bullets\":bullets, \"cover_letter\": letter[:200]})\n",
    "        print(\"Application recorded:\", rec[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fcdb167-1ce9-4223-9867-71caf3b8142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/resumes/resume_1.txt -> ['Java', 'Spring Boot', 'Microservices', 'REST APIs', 'MySQL', 'Docker', 'Kafka'] ['rahul.nair@example.com']\n",
      "data/resumes/resume_10.txt -> ['Python', 'TensorFlow', 'PyTorch', 'NLP', 'Computer Vision', 'Docker'] ['divya.s@example.com']\n",
      "data/resumes/resume_11.txt -> ['MLflow', 'Docker', 'Kubernetes', 'Python', 'Airflow'] ['vikram.s@example.com']\n",
      "data/resumes/resume_12.txt -> ['Docker', 'Kubernetes', 'Terraform', 'AWS', 'CI/CD', 'Linux'] ['ganesh.prasad@example.com']\n",
      "data/resumes/resume_13.txt -> ['AWS', 'GCP', 'Terraform', 'Jenkins', 'Kubernetes'] ['deepa.raj@example.com']\n",
      "data/resumes/resume_14.txt -> ['Selenium', 'Python', 'PyTest', 'Postman', 'CI/CD'] ['kiran.k@example.com']\n",
      "data/resumes/resume_15.txt -> ['Product Strategy', 'Roadmaps', 'PRDs', 'Data Analysis', 'User Research'] ['nisha.v@example.com']\n",
      "data/resumes/resume_16.txt -> ['Figma', 'Wireframes', 'Prototyping', 'User Research', 'Visual Design'] ['harini.s@example.com']\n",
      "data/resumes/resume_17.txt -> ['SIEM', 'Linux', 'Networking', 'Threat Detection'] ['aditya.rao@example.com']\n",
      "data/resumes/resume_18.txt -> ['C++', 'Microcontrollers', 'RTOS', 'UART', 'SPI'] ['meena.k@example.com']\n",
      "data/resumes/resume_19.txt -> ['Unity', 'C#', '3D Modelling', 'Game Physics'] ['arjun.reddy@example.com']\n",
      "data/resumes/resume_2.txt -> ['Python', 'Django', 'Postgres', 'Docker', 'Celery'] ['priya.sharma@email.com']\n",
      "data/resumes/resume_20.txt -> ['Python', 'JavaScript', 'HTML', 'CSS', 'Git'] ['lakshmi.m@example.com']\n",
      "data/resumes/resume_3.txt -> ['Node.js', 'Express.js', 'MongoDB', 'Redis', 'AWS Lambda'] ['amit.sharma@example.com']\n",
      "data/resumes/resume_4.txt -> ['JavaScript', 'React', 'Redux', 'HTML', 'CSS', 'Tailwind'] ['sneha.patil@email.com']\n",
      "data/resumes/resume_5.txt -> ['Vue.js', 'JavaScript', 'HTML', 'CSS', 'Vite', 'REST APIs'] ['karthik.b@example.com']\n",
      "data/resumes/resume_6.txt -> ['React', 'Node.js', 'Express.js', 'MongoDB', 'TypeScript'] ['riya.khanna@example.com']\n",
      "data/resumes/resume_7.txt -> ['Kotlin', 'Android', 'Jetpack Compose', 'MVVM', 'Retrofit'] ['suresh.k@example.com']\n",
      "data/resumes/resume_8.txt -> ['Swift', 'SwiftUI', 'UIKit', 'Combine'] ['aisha.rahman@example.com']\n",
      "data/resumes/resume_9.txt -> ['Python', 'Pandas', 'Numpy', 'Scikit-learn', 'SQL', 'Matplotlib'] ['rohit.menon@example.com']\n"
     ]
    }
   ],
   "source": [
    "#Test notebook cell\n",
    "\n",
    "import json, glob\n",
    "from src.agents.resume_agent import resume_to_json\n",
    "\n",
    "results = {}\n",
    "\n",
    "for file in sorted(glob.glob(\"data/resumes/*.txt\")):\n",
    "    text = open(file).read()\n",
    "    parsed = resume_to_json(text)\n",
    "    results[file] = parsed\n",
    "    print(file, \"->\", parsed[\"skills\"], parsed[\"emails\"])\n",
    "\n",
    "# save parsed outputs\n",
    "with open(\"data/parsed_resumes.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81404c0-d788-4741-b22d-77a4db03929f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
